Whether you’re a researcher, analyst, or data scientist, chances are that at some point you’ve needed to wade through oceans of documents to find the information you’re looking for. To make matters worse, you’re constantly reminded by Google and Bing that there exist better ways to search! For instance, if we search for “When did Marie Curie win her first Nobel Prize?” on Google, we immediately get the correct answer of “1903,” as illustrated in Figure 7-1.
Figure 7-1. A Google search query and corresponding answer snippet
31
In this example, Google first retrieved around 319,000 documents that were relevant to the query, and then performed an additional processing step to extract the answer snippet with the corresponding passage and web page. It’s not hard to see why these answer snippets are useful. For example, if we search for a trickier question like“Which guitar tuning is the best?” Google doesn’t provide an answer, and instead we have to click on one of the web pages returned by the search engine to find it ourselves.1
The general approach behind this technology is called question answering (QA). There are many flavors of QA, but the most common is extractive QA, which involves questions whose answer can be identified as a span of text in a document, where the document might be a web page, legal contract, or news article. The two-stage process of first retrieving relevant documents and then extracting answers from them is also the basis for many modern QA systems, including semantic search engines, intelli‐gent assistants, and automated information extractors. In this chapter, we’ll apply this process to tackle a common problem facing ecommerce websites: helping consumers answer specific queries to evaluate a product. We’ll see that customer reviews can be used as a rich and challenging source of information for QA, and along the way we’ll learn how transformers act as powerful reading comprehension models that can extract meaning from text. Let’s begin by fleshing out the use case.
